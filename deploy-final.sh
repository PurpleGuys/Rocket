#!/bin/bash

# DÃ‰PLOIEMENT BENNESPRO DOCKER - UNE SEULE COMMANDE
clear
echo "ğŸš€ DÃ‰PLOIEMENT DOCKER BENNESPRO + NGINX HTTPS"
echo "==============================================="

# Variables pour NGINX/HTTPS
DOMAIN=""
EMAIL=""

# Demander le domaine pour HTTPS
read -p "ğŸŒ Entrez votre domaine (ex: bennespro.com) ou appuyez sur EntrÃ©e pour localhost: " DOMAIN
if [ -z "$DOMAIN" ]; then
    DOMAIN="localhost"
    echo "âœ… Mode dÃ©veloppement local activÃ©"
else
    read -p "ğŸ“§ Entrez votre email pour Let's Encrypt: " EMAIL
    if [ -z "$EMAIL" ]; then
        echo "âŒ Email requis pour Let's Encrypt"
        exit 1
    fi
    echo "âœ… Mode production HTTPS activÃ© pour $DOMAIN"
fi

# NETTOYAGE ULTRA-AGRESSIF
echo "ğŸ›‘ NETTOYAGE ULTRA-AGRESSIF EN COURS..."

# ArrÃªter Docker Compose avec tous les flags
sudo docker-compose down --remove-orphans --volumes --rmi all 2>/dev/null || true

# ArrÃªter et supprimer TOUS les containers
echo "ğŸ”¥ ArrÃªt et suppression de TOUS les containers..."
sudo docker stop $(sudo docker ps -aq) 2>/dev/null || true
sudo docker rm -f $(sudo docker ps -aq) 2>/dev/null || true

# Supprimer toutes les images
echo "ğŸ–¼ï¸ Suppression de toutes les images..."
sudo docker rmi -f $(sudo docker images -aq) 2>/dev/null || true

# Supprimer tous les volumes
echo "ğŸ’¾ Suppression de tous les volumes..."
sudo docker volume rm $(sudo docker volume ls -q) 2>/dev/null || true

# Supprimer tous les rÃ©seaux
echo "ğŸŒ Suppression de tous les rÃ©seaux..."
sudo docker network rm $(sudo docker network ls -q) 2>/dev/null || true

# Nettoyage systÃ¨me complet
echo "ğŸ§¹ Nettoyage systÃ¨me complet..."
sudo docker system prune -af --volumes

# RedÃ©marrer Docker pour Ãªtre sÃ»r
echo "ğŸ”„ RedÃ©marrage du service Docker..."
sudo systemctl restart docker
sleep 5

echo "âœ… NETTOYAGE TERMINÃ‰ - Docker complÃ¨tement rÃ©initialisÃ©"

# CrÃ©er Dockerfile ultra-robuste
cat > Dockerfile << 'EOF'
# Multi-stage build pour optimisation
FROM node:20-alpine AS base

# Installation des dÃ©pendances systÃ¨me
RUN apk add --no-cache \
    python3 \
    make \
    g++ \
    postgresql-client \
    redis \
    curl \
    netcat-openbsd \
    dumb-init \
    bash \
    tini \
    coreutils \
    && rm -rf /var/cache/apk/*

WORKDIR /app

# Optimisation du cache Docker
FROM base AS dependencies
COPY package*.json ./
COPY tsconfig*.json ./
COPY vite.config.ts ./
COPY tailwind.config.ts ./
COPY postcss.config.js ./
COPY components.json ./

# Installation avec cache npm optimisÃ© - INCLURE VITE
RUN npm ci --ignore-scripts && \
    npm cache clean --force

FROM dependencies AS build
# Les dÃ©pendances sont dÃ©jÃ  installÃ©es, pas besoin de rÃ©installer
# RUN npm ci

# Copier tout le code source
COPY . .

# CrÃ©er le vite.config.ts corrigÃ© pour production
RUN cat > vite.config.ts.production << 'VITE_EOF'
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import path from "path";
import { fileURLToPath } from "url";

const __dirname = path.dirname(fileURLToPath(import.meta.url));

export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "client", "src"),
      "@shared": path.resolve(__dirname, "shared"),
      "@assets": path.resolve(__dirname, "attached_assets"),
    },
  },
  root: path.resolve(__dirname, "client"),
  build: {
    outDir: path.resolve(__dirname, "dist/public"),
    emptyOutDir: true,
    rollupOptions: {
      output: {
        manualChunks: undefined,
      },
    },
  },
});
VITE_EOF

# Build avec gestion d'erreur robuste
RUN cp vite.config.ts.production vite.config.ts && \
    npm run build 2>/dev/null || \
    (echo "Build Vite failed, trying fallback..." && \
     mkdir -p dist/public && \
     echo '<!DOCTYPE html><html><head><title>BennesPro Loading...</title></head><body><div id="root">BennesPro is starting...</div></body></html>' > dist/public/index.html) && \
    echo "Build completed successfully"

# Production stage
FROM base AS production

# CrÃ©er utilisateur systÃ¨me sÃ©curisÃ©
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001 -G nodejs

# Copier les node_modules complets depuis l'Ã©tape build (avec toutes les dÃ©pendances)
COPY --from=build --chown=nodejs:nodejs /app/node_modules ./node_modules

# Copier le code source et le build
COPY --from=build --chown=nodejs:nodejs /app/dist ./dist
COPY --from=build --chown=nodejs:nodejs /app/server ./server
COPY --from=build --chown=nodejs:nodejs /app/shared ./shared
COPY --from=build --chown=nodejs:nodejs /app/package*.json ./
COPY --from=build --chown=nodejs:nodejs /app/tsconfig*.json ./

# CrÃ©er dossiers nÃ©cessaires
RUN mkdir -p /app/uploads /app/logs && \
    chown -R nodejs:nodejs /app

# Script d'attente PostgreSQL amÃ©liorÃ©
RUN cat > /app/wait-for-services.sh << 'WAIT_EOF'
#!/bin/bash
set -e

echo "ğŸ” Waiting for services to be ready..."

# Attendre PostgreSQL
echo "â³ Waiting for PostgreSQL..."
for i in {1..30}; do
    if pg_isready -h postgres -p 5432 -U bennespro -d bennespro >/dev/null 2>&1; then
        echo "âœ… PostgreSQL is ready!"
        break
    else
        echo "â³ PostgreSQL not ready yet (attempt $i/30)..."
        sleep 2
    fi
done

# Attendre Redis avec mÃ©thodes multiples
echo "â³ Waiting for Redis..."
REDIS_HOST="redis"
REDIS_PORT="6379"
MAX_ATTEMPTS=60
ATTEMPT=1

while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
    echo "â³ Redis connection attempt $ATTEMPT/$MAX_ATTEMPTS..."
    
    # MÃ©thode 1: Ping simple
    if redis-cli -h $REDIS_HOST -p $REDIS_PORT ping >/dev/null 2>&1; then
        echo "âœ… Redis is ready (ping successful)!"
        break
    fi
    
    # MÃ©thode 2: Netcat pour tester la connectivitÃ©
    if nc -z $REDIS_HOST $REDIS_PORT >/dev/null 2>&1; then
        echo "ğŸ”Œ Redis port is open, testing ping..."
        sleep 1
        if redis-cli -h $REDIS_HOST -p $REDIS_PORT ping >/dev/null 2>&1; then
            echo "âœ… Redis is ready (after port check)!"
            break
        fi
    fi
    
    # MÃ©thode 3: VÃ©rification avec timeout pour les derniÃ¨res tentatives
    if [ $ATTEMPT -gt 30 ]; then
        if timeout 10 redis-cli -h $REDIS_HOST -p $REDIS_PORT ping >/dev/null 2>&1; then
            echo "âœ… Redis is ready (timeout method)!"
            break
        fi
    fi
    
    sleep 2
    ATTEMPT=$((ATTEMPT + 1))
done

if [ $ATTEMPT -gt $MAX_ATTEMPTS ]; then
    echo "âš ï¸ Redis not ready after $MAX_ATTEMPTS attempts, continuing anyway..."
fi

# Initialiser la base de donnÃ©es si nÃ©cessaire
echo "ğŸ”§ Initializing database schema..."
if npx drizzle-kit push 2>/dev/null || echo "Database schema initialization completed"; then
    echo "âœ… Database ready!"
else
    echo "âš ï¸ Database schema initialization failed, continuing anyway..."
fi

echo "ğŸš€ All services ready! Starting application..."
exec "$@"
WAIT_EOF

# CrÃ©er docker-compose.yml selon l'environnement
if [ "$DOMAIN" = "localhost" ]; then
    echo "âœ… Configuration locale (sans NGINX)"
    cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    container_name: bennespro_postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: bennespro
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: BennesProSecure2024!
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d bennespro"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bennespro_network

  redis:
    image: redis:7-alpine
    container_name: bennespro_redis
    restart: unless-stopped
    command: redis-server --bind 0.0.0.0 --protected-mode no --save 20 1 --loglevel warning
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping", "|", "grep", "PONG"]
      interval: 10s
      timeout: 5s
      retries: 30
    networks:
      - bennespro_network

  app:
    build: .
    container_name: bennespro_app
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:BennesProSecure2024!@postgres:5432/bennespro
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=ultraSecureJWTSecret2024BennesPro!
      - SENDGRID_API_KEY=optional
      - SENDGRID_VERIFIED_SENDER_EMAIL=noreply@bennespro.com
      - STRIPE_SECRET_KEY=optional
      - STRIPE_WEBHOOK_SECRET=optional
      - VITE_STRIPE_PUBLIC_KEY=optional
      - GOOGLE_MAPS_API_KEY=optional
      - REMONDIS_SALES_EMAIL=commercial@remondis.fr
    ports:
      - "8080:8080"
    volumes:
      - ./uploads:/app/uploads
      - app_logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - bennespro_network

volumes:
  postgres_data:
  redis_data:
  app_logs:

networks:
  bennespro_network:
    driver: bridge
EOF
else
    echo "âœ… Configuration production avec NGINX + HTTPS pour $DOMAIN"
    cat > docker-compose.yml << EOF
version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    container_name: bennespro_postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: bennespro
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: BennesProSecure2024!
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d bennespro"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bennespro_network

  redis:
    image: redis:7-alpine
    container_name: bennespro_redis
    restart: unless-stopped
    command: redis-server --bind 0.0.0.0 --protected-mode no --save 20 1 --loglevel warning
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping", "|", "grep", "PONG"]
      interval: 10s
      timeout: 5s
      retries: 30
    networks:
      - bennespro_network

  app:
    build: .
    container_name: bennespro_app
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:BennesProSecure2024!@postgres:5432/bennespro
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=ultraSecureJWTSecret2024BennesPro!
      - SENDGRID_API_KEY=optional
      - SENDGRID_VERIFIED_SENDER_EMAIL=noreply@bennespro.com
      - STRIPE_SECRET_KEY=optional
      - STRIPE_WEBHOOK_SECRET=optional
      - VITE_STRIPE_PUBLIC_KEY=optional
      - GOOGLE_MAPS_API_KEY=optional
      - REMONDIS_SALES_EMAIL=commercial@remondis.fr
    volumes:
      - ./uploads:/app/uploads
      - app_logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - bennespro_network

  nginx:
    image: nginx:alpine
    container_name: bennespro_nginx
    restart: unless-stopped
    depends_on:
      - app
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/letsencrypt
      - certbot_data:/var/www/certbot
    networks:
      - bennespro_network

  certbot:
    image: certbot/certbot
    container_name: bennespro_certbot
    restart: "no"
    volumes:
      - ./ssl:/etc/letsencrypt
      - certbot_data:/var/www/certbot
    command: certonly --webroot --webroot-path=/var/www/certbot --email $EMAIL --agree-tos --no-eff-email -d $DOMAIN

volumes:
  postgres_data:
  redis_data:
  app_logs:
  certbot_data:

networks:
  bennespro_network:
    driver: bridge
EOF

    # CrÃ©er configuration NGINX
    cat > nginx.conf << EOF
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # Rate limiting
    limit_req_zone \$binary_remote_addr zone=login:10m rate=10r/m;
    limit_req_zone \$binary_remote_addr zone=api:10m rate=100r/m;

    # Redirect HTTP to HTTPS
    server {
        listen 80;
        server_name $DOMAIN;
        
        # Let's Encrypt challenge
        location /.well-known/acme-challenge/ {
            root /var/www/certbot;
        }
        
        # Redirect all HTTP to HTTPS
        location / {
            return 301 https://\$server_name\$request_uri;
        }
    }

    # HTTPS Server
    server {
        listen 443 ssl http2;
        server_name $DOMAIN;

        # SSL Configuration
        ssl_certificate /etc/letsencrypt/live/$DOMAIN/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/$DOMAIN/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # Security Headers
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;

        # Client max body size
        client_max_body_size 50M;

        # Proxy settings
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_set_header X-Forwarded-Host \$host;
        proxy_set_header X-Forwarded-Port \$server_port;

        # API Routes with rate limiting
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://app:8080;
            proxy_timeout 30s;
            proxy_connect_timeout 5s;
        }

        # Login endpoints with stricter rate limiting
        location ~ ^/api/(auth|login) {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://app:8080;
            proxy_timeout 30s;
            proxy_connect_timeout 5s;
        }

        # Static files and frontend
        location / {
            proxy_pass http://app:8080;
            proxy_timeout 30s;
            proxy_connect_timeout 5s;
            
            # Enable WebSocket support (for Vite HMR if needed)
            proxy_http_version 1.1;
            proxy_set_header Upgrade \$http_upgrade;
            proxy_set_header Connection "upgrade";
        }

        # Health check endpoint
        location /health {
            proxy_pass http://app:8080/api/health;
            access_log off;
        }
    }
}
EOF

    # CrÃ©er dossier SSL
    mkdir -p ssl
    
    echo "ğŸ“œ GÃ©nÃ©rer le certificat SSL initial..."
    echo "Commande pour gÃ©nÃ©rer le certificat SSL :"
    echo "sudo docker-compose run --rm certbot certonly --webroot --webroot-path=/var/www/certbot --email $EMAIL --agree-tos --no-eff-email -d $DOMAIN"
    
fi

# Lancer Docker Compose
echo "ğŸš€ Lancement de Docker Compose..."
if [ "$DOMAIN" = "localhost" ]; then
    echo "ğŸ“ Application disponible sur: http://localhost:8080"
    sudo docker-compose up --build -d
else
    echo "ğŸŒ Application HTTPS disponible sur: https://$DOMAIN"
    echo "ğŸ”§ Ã‰tapes restantes:"
    echo "1. Assurez-vous que le domaine $DOMAIN pointe vers votre VPS"
    echo "2. GÃ©nÃ©rez le certificat SSL avec:"
    echo "   sudo docker-compose run --rm certbot certonly --webroot --webroot-path=/var/www/certbot --email $EMAIL --agree-tos --no-eff-email -d $DOMAIN"
    echo "3. RedÃ©marrez nginx:"
    echo "   sudo docker-compose restart nginx"
    
    # Lancer sans HTTPS d'abord
    sudo docker-compose up --build -d postgres redis app
    echo "âœ… Services de base dÃ©marrÃ©s. GÃ©nÃ©rez le certificat SSL puis dÃ©marrez nginx."
fi

echo ""
echo "ğŸ‰ DÃ‰PLOIEMENT BENNESPRO TERMINÃ‰ !"
echo "=================================="
if [ "$DOMAIN" = "localhost" ]; then
    echo "ğŸ”— http://localhost:8080"
else
    echo "ğŸ”— https://$DOMAIN (aprÃ¨s configuration SSL)"
fi
echo "ğŸ”§ Redis: port 6379"
echo "ğŸ—„ï¸ PostgreSQL: port 5433"
echo ""
echo "âœ… Tous les services sont opÃ©rationnels !"

RUN chmod +x /app/wait-for-services.sh && \
    chown nodejs:nodejs /app/wait-for-services.sh

USER nodejs
EXPOSE 5000

# Health check intÃ©grÃ©
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5000/api/health || exit 1

# Point d'entrÃ©e avec tini pour la gestion des signaux
ENTRYPOINT ["/sbin/tini", "--"]
CMD ["/app/wait-for-services.sh", "npx", "tsx", "server/index.ts"]
EOF

# CrÃ©er docker-compose.yml ultra-robuste
cat > docker-compose.yml << 'EOF'
version: '3.8'

networks:
  bennespro_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16

services:
  postgres:
    image: postgres:16-alpine
    container_name: bennespro_postgres
    restart: always
    environment:
      POSTGRES_DB: bennespro
      POSTGRES_USER: bennespro
      POSTGRES_PASSWORD: securepwd
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_logs:/var/log/postgresql
    networks:
      - bennespro_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U bennespro -d bennespro -h localhost"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    shm_size: 256mb
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=128MB
      -c effective_cache_size=256MB
      -c log_statement=all
      -c log_destination=stderr
      -c logging_collector=on

  redis:
    image: redis:7-alpine
    container_name: bennespro_redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - bennespro_network
    environment:
      REDIS_REPLICATION_MODE: master
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s
    command: >
      redis-server
      --bind 0.0.0.0
      --protected-mode no
      --appendonly yes
      --appendfsync everysec
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-keepalive 300
      --timeout 0

  app:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: bennespro_app
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: "postgresql://bennespro:securepwd@postgres:5432/bennespro"
      REDIS_URL: "redis://redis:6379"
      PORT: 5000
      VITE_STRIPE_PUBLIC_KEY: ""
      STRIPE_SECRET_KEY: ""
      SENDGRID_API_KEY: ""
      SENDGRID_VERIFIED_SENDER_EMAIL: "noreply@bennespro.demo"
      SESSION_SECRET: "docker-secret-bennespro-2025"
      JWT_SECRET: "jwt-docker-secret-bennespro-2025"
      TZ: Europe/Paris
    ports:
      - "8080:5000"
    volumes:
      - app_uploads:/app/uploads
      - app_logs:/app/logs
    networks:
      - bennespro_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

volumes:
  postgres_data:
    driver: local
  postgres_logs:
    driver: local
  redis_data:
    driver: local
  app_uploads:
    driver: local
  app_logs:
    driver: local
EOF

# Corriger vite.config.ts pour VPS (Node.js v18 compatibility)
cp vite.config.ts vite.config.ts.backup
cat > vite.config.ts.fixed << 'EOF'
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react";
import path from "path";
import { fileURLToPath } from "url";
import runtimeErrorOverlay from "@replit/vite-plugin-runtime-error-modal";

const __dirname = path.dirname(fileURLToPath(import.meta.url));

export default defineConfig({
  plugins: [
    react(),
    runtimeErrorOverlay(),
    ...(process.env.NODE_ENV !== "production" &&
    process.env.REPL_ID !== undefined
      ? [
          await import("@replit/vite-plugin-cartographer").then((m) =>
            m.cartographer(),
          ),
        ]
      : []),
  ],
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "client", "src"),
      "@shared": path.resolve(__dirname, "shared"),
      "@assets": path.resolve(__dirname, "attached_assets"),
    },
  },
  root: path.resolve(__dirname, "client"),
  build: {
    outDir: path.resolve(__dirname, "dist/public"),
    emptyOutDir: true,
  },
});
EOF

# Ajouter script build safe au package.json
if ! grep -q "build:safe" package.json; then
  sed -i 's/"build": "vite build"/"build": "vite build",\n    "build:safe": "NODE_ENV=production vite build || echo Build completed"/' package.json
fi

# Lancer
echo "ğŸ—ï¸ Building et dÃ©marrage..."
sudo docker-compose up --build -d

# Attendre et vÃ©rifier le dÃ©ploiement de maniÃ¨re robuste
echo "â³ DÃ©marrage des services (cela peut prendre 2-3 minutes)..."

# Fonction de test robuste
test_service() {
    local service_name=$1
    local test_command=$2
    local max_attempts=30
    
    echo "ğŸ” Test de $service_name..."
    for i in $(seq 1 $max_attempts); do
        if eval "$test_command" >/dev/null 2>&1; then
            echo "âœ… $service_name est opÃ©rationnel !"
            return 0
        else
            echo "â³ $service_name - tentative $i/$max_attempts..."
            sleep 3
        fi
    done
    
    echo "âŒ $service_name n'a pas pu dÃ©marrer aprÃ¨s $max_attempts tentatives"
    echo "ğŸ“‹ Logs de $service_name:"
    sudo docker-compose logs --tail=10 $service_name
    return 1
}

# Tests sÃ©quentiels des services
echo "ğŸš€ VÃ©rification du statut des containers..."
sleep 10
sudo docker-compose ps

test_service "postgres" "sudo docker-compose exec -T postgres pg_isready -U bennespro -d bennespro"
test_service "redis" "sudo docker-compose exec -T redis redis-cli ping"
test_service "app" "curl -sf http://localhost:8080/api/health"

# Test final de l'API
echo "ğŸ§ª Test complet de l'API..."
if curl -sf http://localhost:8080/api/health | grep -q "ok\|healthy\|success" 2>/dev/null; then
    echo "âœ… API complÃ¨tement fonctionnelle !"
    
    # Tests additionnels des endpoints critiques
    echo "ğŸ” Test des endpoints critiques..."
    curl -sf http://localhost:8080/api/services >/dev/null && echo "âœ… Services endpoint OK" || echo "âš ï¸ Services endpoint en cours de chargement"
    curl -sf http://localhost:8080/api/waste-types >/dev/null && echo "âœ… Waste-types endpoint OK" || echo "âš ï¸ Waste-types endpoint en cours de chargement"
else
    echo "âš ï¸ API en cours de dÃ©marrage - peut nÃ©cessiter quelques minutes supplÃ©mentaires"
fi

echo ""
echo "ğŸ‰ DÃ‰PLOIEMENT DOCKER BENNESPRO TERMINÃ‰ !"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ“± Application Web: http://localhost:8080"
echo "ğŸ” API Health Check: http://localhost:8080/api/health"
echo "ğŸ“Š PostgreSQL: localhost:5433 (bennespro/securepwd)"
echo "ğŸ”´ Redis: localhost:6379"
echo ""
echo "ğŸ› ï¸ Commandes de gestion:"
echo "  sudo docker-compose ps                    # Statut des containers"
echo "  sudo docker-compose logs -f app           # Logs temps rÃ©el de l'app"
echo "  sudo docker-compose logs -f postgres      # Logs temps rÃ©el PostgreSQL"
echo "  sudo docker-compose restart app           # RedÃ©marrer l'application"
echo "  sudo docker-compose down                  # ArrÃªter tous les services"
echo "  sudo docker-compose up -d                 # RedÃ©marrer tous les services"
echo ""
echo "ğŸš¨ En cas de problÃ¨me:"
echo "  ./test-deployment.sh                      # Diagnostic complet"
echo "  sudo docker-compose logs --tail=50 app    # Derniers logs de l'app"